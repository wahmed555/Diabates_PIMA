{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from keras import layers\n",
    "# from keras import models\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      6  148  72  35    0  33.6  0.627  50  1\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "5     3   78  50  32   88  31.0  0.248  26  1\n",
       "6    10  115   0   0    0  35.3  0.134  29  0\n",
       "7     2  197  70  45  543  30.5  0.158  53  1\n",
       "8     8  125  96   0    0   0.0  0.232  54  1\n",
       "9     4  110  92   0    0  37.6  0.191  30  0\n",
       "10   10  168  74   0    0  38.0  0.537  34  1\n",
       "11   10  139  80   0    0  27.1  1.441  57  0\n",
       "12    1  189  60  23  846  30.1  0.398  59  1\n",
       "13    5  166  72  19  175  25.8  0.587  51  1\n",
       "14    7  100   0   0    0  30.0  0.484  32  1\n",
       "15    0  118  84  47  230  45.8  0.551  31  1\n",
       "16    7  107  74   0    0  29.6  0.254  31  1\n",
       "17    1  103  30  38   83  43.3  0.183  33  0\n",
       "18    1  115  70  30   96  34.6  0.529  32  1\n",
       "19    3  126  88  41  235  39.3  0.704  27  0\n",
       "20    8   99  84   0    0  35.4  0.388  50  0\n",
       "21    7  196  90   0    0  39.8  0.451  41  1\n",
       "22    9  119  80  35    0  29.0  0.263  29  1\n",
       "23   11  143  94  33  146  36.6  0.254  51  1\n",
       "24   10  125  70  26  115  31.1  0.205  41  1\n",
       "25    7  147  76   0    0  39.4  0.257  43  1\n",
       "26    1   97  66  15  140  23.2  0.487  22  0\n",
       "27   13  145  82  19  110  22.2  0.245  57  0\n",
       "28    5  117  92   0    0  34.1  0.337  38  0\n",
       "29    5  109  75  26    0  36.0  0.546  60  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "737   2   99  60  17  160  36.6  0.453  21  0\n",
       "738   1  102  74   0    0  39.5  0.293  42  1\n",
       "739  11  120  80  37  150  42.3  0.785  48  1\n",
       "740   3  102  44  20   94  30.8  0.400  26  0\n",
       "741   1  109  58  18  116  28.5  0.219  22  0\n",
       "742   9  140  94   0    0  32.7  0.734  45  1\n",
       "743  13  153  88  37  140  40.6  1.174  39  0\n",
       "744  12  100  84  33  105  30.0  0.488  46  0\n",
       "745   1  147  94  41    0  49.3  0.358  27  1\n",
       "746   1   81  74  41   57  46.3  1.096  32  0\n",
       "747   3  187  70  22  200  36.4  0.408  36  1\n",
       "748   6  162  62   0    0  24.3  0.178  50  1\n",
       "749   4  136  70   0    0  31.2  1.182  22  1\n",
       "750   1  121  78  39   74  39.0  0.261  28  0\n",
       "751   3  108  62  24    0  26.0  0.223  25  0\n",
       "752   0  181  88  44  510  43.3  0.222  26  1\n",
       "753   8  154  78  32    0  32.4  0.443  45  1\n",
       "754   1  128  88  39  110  36.5  1.057  37  1\n",
       "755   7  137  90  41    0  32.0  0.391  39  0\n",
       "756   0  123  72   0    0  36.3  0.258  52  1\n",
       "757   1  106  76   0    0  37.5  0.197  26  0\n",
       "758   6  190  92   0    0  35.5  0.278  66  1\n",
       "759   2   88  58  26   16  28.4  0.766  22  0\n",
       "760   9  170  74  31    0  44.0  0.403  43  1\n",
       "761   9   89  62   0    0  22.5  0.142  33  0\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       6  148  72  35    0  33.6  0.627  50  1\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "5     3   78  50  32   88  31.0  0.248  26  1\n",
       "6    10  115   0   0    0  35.3  0.134  29  0\n",
       "7     2  197  70  45  543  30.5  0.158  53  1\n",
       "8     8  125  96   0    0   0.0  0.232  54  1\n",
       "9     4  110  92   0    0  37.6  0.191  30  0\n",
       "10   10  168  74   0    0  38.0  0.537  34  1\n",
       "11   10  139  80   0    0  27.1  1.441  57  0\n",
       "12    1  189  60  23  846  30.1  0.398  59  1\n",
       "13    5  166  72  19  175  25.8  0.587  51  1\n",
       "14    7  100   0   0    0  30.0  0.484  32  1\n",
       "15    0  118  84  47  230  45.8  0.551  31  1\n",
       "16    7  107  74   0    0  29.6  0.254  31  1\n",
       "17    1  103  30  38   83  43.3  0.183  33  0\n",
       "18    1  115  70  30   96  34.6  0.529  32  1\n",
       "19    3  126  88  41  235  39.3  0.704  27  0\n",
       "20    8   99  84   0    0  35.4  0.388  50  0\n",
       "21    7  196  90   0    0  39.8  0.451  41  1\n",
       "22    9  119  80  35    0  29.0  0.263  29  1\n",
       "23   11  143  94  33  146  36.6  0.254  51  1\n",
       "24   10  125  70  26  115  31.1  0.205  41  1\n",
       "25    7  147  76   0    0  39.4  0.257  43  1\n",
       "26    1   97  66  15  140  23.2  0.487  22  0\n",
       "27   13  145  82  19  110  22.2  0.245  57  0\n",
       "28    5  117  92   0    0  34.1  0.337  38  0\n",
       "29    5  109  75  26    0  36.0  0.546  60  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "737   2   99  60  17  160  36.6  0.453  21  0\n",
       "738   1  102  74   0    0  39.5  0.293  42  1\n",
       "739  11  120  80  37  150  42.3  0.785  48  1\n",
       "740   3  102  44  20   94  30.8  0.400  26  0\n",
       "741   1  109  58  18  116  28.5  0.219  22  0\n",
       "742   9  140  94   0    0  32.7  0.734  45  1\n",
       "743  13  153  88  37  140  40.6  1.174  39  0\n",
       "744  12  100  84  33  105  30.0  0.488  46  0\n",
       "745   1  147  94  41    0  49.3  0.358  27  1\n",
       "746   1   81  74  41   57  46.3  1.096  32  0\n",
       "747   3  187  70  22  200  36.4  0.408  36  1\n",
       "748   6  162  62   0    0  24.3  0.178  50  1\n",
       "749   4  136  70   0    0  31.2  1.182  22  1\n",
       "750   1  121  78  39   74  39.0  0.261  28  0\n",
       "751   3  108  62  24    0  26.0  0.223  25  0\n",
       "752   0  181  88  44  510  43.3  0.222  26  1\n",
       "753   8  154  78  32    0  32.4  0.443  45  1\n",
       "754   1  128  88  39  110  36.5  1.057  37  1\n",
       "755   7  137  90  41    0  32.0  0.391  39  0\n",
       "756   0  123  72   0    0  36.3  0.258  52  1\n",
       "757   1  106  76   0    0  37.5  0.197  26  0\n",
       "758   6  190  92   0    0  35.5  0.278  66  1\n",
       "759   2   88  58  26   16  28.4  0.766  22  0\n",
       "760   9  170  74  31    0  44.0  0.403  43  1\n",
       "761   9   89  62   0    0  22.5  0.142  33  0\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1.len()\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(df1)\n",
    "k = 4\n",
    "num_validation_samples = len(df1) // k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-542e5d83c5d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_validation_samples\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_validation_samples\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfold\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mvalidation_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold: num_validation_samples * (fold + 1)]\n",
    "    training_data = np.vstack((data[:num_validation_samples * fold] , data[num_validation_samples * (fold + 1):]))\n",
    "    \n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_score = np.average(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "X=dataset[:,0:8]\n",
    "Y=dataset[:,8]\n",
    "# now create a model:\n",
    "#create model\n",
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 3.7085 - acc: 0.5990\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.9356 - acc: 0.5938\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 382us/step - loss: 0.7470 - acc: 0.6406\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.7115 - acc: 0.6576\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.6817 - acc: 0.6771\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 373us/step - loss: 0.6508 - acc: 0.6797\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 369us/step - loss: 0.6489 - acc: 0.6706\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.6364 - acc: 0.6914\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 382us/step - loss: 0.6236 - acc: 0.6901\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.6297 - acc: 0.6784\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.6463 - acc: 0.6758\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.6381 - acc: 0.6706\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.6254 - acc: 0.6771\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.6179 - acc: 0.7031\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.6019 - acc: 0.6979\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 390us/step - loss: 0.5876 - acc: 0.7031\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.5847 - acc: 0.6992\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.6000 - acc: 0.6823\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.5801 - acc: 0.7070\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.5806 - acc: 0.7201\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.5689 - acc: 0.7148\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.5825 - acc: 0.6966\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 375us/step - loss: 0.5739 - acc: 0.7109\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.5679 - acc: 0.7331\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.5577 - acc: 0.7383\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.5707 - acc: 0.7044\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.5559 - acc: 0.7201\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.5556 - acc: 0.7305\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 401us/step - loss: 0.5741 - acc: 0.7135\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.5608 - acc: 0.7227\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.5689 - acc: 0.7174\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 410us/step - loss: 0.5628 - acc: 0.7161\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 444us/step - loss: 0.5521 - acc: 0.7174\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.5493 - acc: 0.7292\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 447us/step - loss: 0.5503 - acc: 0.7214\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 431us/step - loss: 0.5647 - acc: 0.7044\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.5337 - acc: 0.7396\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 375us/step - loss: 0.5406 - acc: 0.7253\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.5464 - acc: 0.7266\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.5447 - acc: 0.7266\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.5431 - acc: 0.7305\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.5375 - acc: 0.7409\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.5317 - acc: 0.7474\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5340 - acc: 0.7422\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.5314 - acc: 0.7500\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5305 - acc: 0.7513\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.5324 - acc: 0.7409\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.5322 - acc: 0.7422\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5335 - acc: 0.7435\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.5265 - acc: 0.7370\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.5262 - acc: 0.7487\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5330 - acc: 0.7435\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.5389 - acc: 0.7448\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.5384 - acc: 0.7240\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.5215 - acc: 0.7565\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 350us/step - loss: 0.5283 - acc: 0.7474\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.5306 - acc: 0.7409\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5213 - acc: 0.7539\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.5124 - acc: 0.7669 0s - loss: 0.5271 - acc: 0.\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5344 - acc: 0.7487\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.5241 - acc: 0.7422\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.5161 - acc: 0.7578\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.5420 - acc: 0.7344\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.5318 - acc: 0.7448\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.5179 - acc: 0.7526\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.5057 - acc: 0.7552\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.5157 - acc: 0.7370\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 337us/step - loss: 0.5104 - acc: 0.7500\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5109 - acc: 0.7500\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.5331 - acc: 0.7188\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5168 - acc: 0.7526\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.5141 - acc: 0.7591\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5148 - acc: 0.7513\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 246us/step - loss: 0.5087 - acc: 0.7669\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5086 - acc: 0.7617\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.5102 - acc: 0.7604\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.5134 - acc: 0.7643\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.5100 - acc: 0.7487\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 222us/step - loss: 0.5110 - acc: 0.7383\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 222us/step - loss: 0.5046 - acc: 0.7669\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.5016 - acc: 0.7747\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4996 - acc: 0.7578\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 227us/step - loss: 0.4967 - acc: 0.7656\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 233us/step - loss: 0.4944 - acc: 0.7565\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5029 - acc: 0.7578\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.5061 - acc: 0.7539\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 205us/step - loss: 0.4963 - acc: 0.7591\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 197us/step - loss: 0.4979 - acc: 0.7656\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.5024 - acc: 0.7721\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.5092 - acc: 0.7539\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4954 - acc: 0.7617\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5092 - acc: 0.7474\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.4978 - acc: 0.7656\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 246us/step - loss: 0.4947 - acc: 0.7656\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 228us/step - loss: 0.5026 - acc: 0.7487\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.4889 - acc: 0.7656\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 206us/step - loss: 0.4968 - acc: 0.7773\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.4870 - acc: 0.7682\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4876 - acc: 0.7747\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4836 - acc: 0.7865\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 218us/step - loss: 0.4873 - acc: 0.7773\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.4965 - acc: 0.7591\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 225us/step - loss: 0.4958 - acc: 0.7591\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.4898 - acc: 0.7865\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 233us/step - loss: 0.5281 - acc: 0.7487\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.4908 - acc: 0.7760\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 236us/step - loss: 0.4887 - acc: 0.7773\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.5012 - acc: 0.7669\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.4853 - acc: 0.7591\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.4868 - acc: 0.7630\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4816 - acc: 0.7826\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 217us/step - loss: 0.4904 - acc: 0.7812\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 219us/step - loss: 0.4967 - acc: 0.7461\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.4895 - acc: 0.7591\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.4900 - acc: 0.7682\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4884 - acc: 0.7682\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 219us/step - loss: 0.4889 - acc: 0.7656\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.4844 - acc: 0.7786\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4821 - acc: 0.7708\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4932 - acc: 0.7799\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.4900 - acc: 0.7734\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4806 - acc: 0.7839\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 225us/step - loss: 0.4830 - acc: 0.7708\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4820 - acc: 0.7799\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4825 - acc: 0.7773\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4785 - acc: 0.7760\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.4849 - acc: 0.7695\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 228us/step - loss: 0.4690 - acc: 0.7799\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4773 - acc: 0.7760\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 233us/step - loss: 0.4679 - acc: 0.7891\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.4791 - acc: 0.7708\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.4790 - acc: 0.7812\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 240us/step - loss: 0.4813 - acc: 0.7695\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 233us/step - loss: 0.4821 - acc: 0.7773\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.4720 - acc: 0.7786\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 215us/step - loss: 0.4705 - acc: 0.7786\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.4661 - acc: 0.7904\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 233us/step - loss: 0.4773 - acc: 0.7917\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.4653 - acc: 0.7786\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.4781 - acc: 0.7786\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.4708 - acc: 0.7878\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 204us/step - loss: 0.4821 - acc: 0.7682\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.4709 - acc: 0.7852\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.4727 - acc: 0.7891\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4834 - acc: 0.7656\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 225us/step - loss: 0.4923 - acc: 0.7708\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4801 - acc: 0.7812\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 218us/step - loss: 0.4679 - acc: 0.7826\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 214us/step - loss: 0.4713 - acc: 0.7669\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.4761 - acc: 0.7865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9b3a533da0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 63us/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-2d92a8717abb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n %s: %2f  \"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(X,Y)\n",
    "print(\"\\n %s: %2f  \"%(model.metrics[1],score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Perform Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X)\n",
    "#round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
